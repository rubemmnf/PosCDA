{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03c_ExercicioClassificacao.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hExOp5OvKZlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c01c97-7f15-451d-abfb-0d7dc83b3f9e"
      },
      "source": [
        "!git clone https://github.com/valmirf/mineracao_textual.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mineracao_textual'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 148 (delta 74), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (148/148), 4.14 MiB | 4.24 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGfG7BHb-W-r"
      },
      "source": [
        "# Exercício: Classificando Petição Inicial de Problemas com Viagens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3IMacGw8BP6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "271f4dc3-3519-4bde-8a8e-4411632506ae"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = data = pd.read_csv(\"mineracao_textual/Dados/dataset_ness_law.csv\")\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>objeto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fatos joão césar sala eldorado contagem marque...</td>\n",
              "      <td>Extravio de Bagagem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fatos fatos ocorridos trecho conforme document...</td>\n",
              "      <td>Doméstico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fatos autores presente ação programaram meses ...</td>\n",
              "      <td>Atraso ou Cancelamento de Voo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fatos objetivando viajar porto alegre particip...</td>\n",
              "      <td>Alteração na Malha Aérea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fatos autor comprou passagem retorno casa após...</td>\n",
              "      <td>Extravio de Bagagem</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 txt                         objeto\n",
              "0  fatos joão césar sala eldorado contagem marque...            Extravio de Bagagem\n",
              "1  fatos fatos ocorridos trecho conforme document...                      Doméstico\n",
              "2  fatos autores presente ação programaram meses ...  Atraso ou Cancelamento de Voo\n",
              "3  fatos objetivando viajar porto alegre particip...       Alteração na Malha Aérea\n",
              "4  fatos autor comprou passagem retorno casa após...            Extravio de Bagagem"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIcfqQGH-G_F"
      },
      "source": [
        "Analise a distribuição das classes, indicadas na coluna `Class Name`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_NLk1Ev-qqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be22cf11-2026-4c77-e46f-d9fa952d4cd8"
      },
      "source": [
        "# sua resposta\n",
        "df['objeto'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Atraso ou Cancelamento de Voo      136\n",
              "Alteração na Malha Aérea            79\n",
              "Doméstico                           59\n",
              "Extravio de Bagagem                 49\n",
              "Inconformidade de Taxas             26\n",
              "Embarque Impedido                   16\n",
              "Equívoco ou Atraso no Reembolso      9\n",
              "Danificação de Bagagem               9\n",
              "Provisório                           8\n",
              "Erro ou Alteração na Reserva         6\n",
              "Outros                               3\n",
              "Name: objeto, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPzg6Wcs-1rl"
      },
      "source": [
        "Analise a distribuição do comprimento dos reviews, plote um histograma (`DataFrame.plot.hist()`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAiZekzx-0-N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "02f20d44-19ab-4d24-bda1-8a4e3f9deee4"
      },
      "source": [
        "# sua resposta\n",
        "df['TamanhoObjeto'] = df['objeto'].apply(lambda x: len(x))\n",
        "df['TamanhoObjeto'].plot.hist()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0adedba850>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfm1MeotAh4Z"
      },
      "source": [
        "Aplique a função de encoding de rótulos categóricos do Sklearn ([LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)) para converter os rótulos de classe em numeros. Salve em uma coluna adicional no dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkVpxbybA9fm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "c1a073bc-9dae-4077-b019-f95748f65170"
      },
      "source": [
        "# descartar classes minoritarias\n",
        "major_classes = list(df['objeto'].value_counts()[0:4].index)\n",
        "majority      = df.loc[df['objeto'].isin(major_classes),]\n",
        "minority      = df.loc[~df['objeto'].isin(major_classes),]\n",
        "\n",
        "print('\\n',5*'=', 'major classes: \\n',    majority['objeto'].value_counts()[0:4])\n",
        "print('\\n',5*'=', 'minority classes: \\n', minority['objeto'].value_counts()[4:])\n",
        "\n",
        "majority.head()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(majority['objeto'])\n",
        "majority['label'] = le.transform(majority['objeto'])\n",
        "majority.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ===== major classes: \n",
            " Atraso ou Cancelamento de Voo    136\n",
            "Alteração na Malha Aérea          79\n",
            "Doméstico                         59\n",
            "Extravio de Bagagem               49\n",
            "Name: objeto, dtype: int64\n",
            "\n",
            " ===== minority classes: \n",
            " Provisório                      8\n",
            "Erro ou Alteração na Reserva    6\n",
            "Outros                          3\n",
            "Name: objeto, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>objeto</th>\n",
              "      <th>TamanhoObjeto</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fatos joão césar sala eldorado contagem marque...</td>\n",
              "      <td>Extravio de Bagagem</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fatos fatos ocorridos trecho conforme document...</td>\n",
              "      <td>Doméstico</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fatos autores presente ação programaram meses ...</td>\n",
              "      <td>Atraso ou Cancelamento de Voo</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fatos objetivando viajar porto alegre particip...</td>\n",
              "      <td>Alteração na Malha Aérea</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fatos autor comprou passagem retorno casa após...</td>\n",
              "      <td>Extravio de Bagagem</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 txt  ... label\n",
              "0  fatos joão césar sala eldorado contagem marque...  ...     3\n",
              "1  fatos fatos ocorridos trecho conforme document...  ...     2\n",
              "2  fatos autores presente ação programaram meses ...  ...     1\n",
              "3  fatos objetivando viajar porto alegre particip...  ...     0\n",
              "4  fatos autor comprou passagem retorno casa após...  ...     3\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3oDZj-l8o-7"
      },
      "source": [
        "Aplique o pipeline de pré-processamento utilizando o NLTK ou SpaCy (tokenização, remoção de stopwords, e/ou lematização e/ou stemming)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jWJ-CsH_2KV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0766c6f6-13aa-4019-db68-19ec784be9c0"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt') # Punkt sentence tokenizer\n",
        "from nltk.probability import FreqDist"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtotaPRhuAFS",
        "outputId": "bf3b578a-d1a8-4b78-a8ef-4c447ed91d43"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words=set(stopwords.words(\"portuguese\"))\n",
        "print(stop_words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "{'você', 'hajamos', 'eram', 'tínhamos', 'estiver', 'houverem', 'mas', 'seu', 'pela', 'quem', 'aqueles', 'teria', 'tive', 'foi', 'houvemos', 'deles', 'haja', 'suas', 'sou', 'também', 'tinha', 'tivéramos', 'houvéssemos', 'houveriam', 'tém', 'meus', 'estavam', 'seria', 'aos', 'estiverem', 'e', 'minhas', 'estivermos', 'formos', 'se', 'tua', 'forem', 'tu', 'tivesse', 'um', 'não', 'já', 'fôssemos', 'estivéssemos', 'essas', 'for', 'até', 'minha', 'entre', 'lhe', 'só', 'em', 'tivéssemos', 'houvermos', 'tivessem', 'dos', 'os', 'está', 'essa', 'tuas', 'esse', 'nossos', 'seriam', 'como', 'pelo', 'isso', 'pelos', 'havemos', 'tem', 'tivermos', 'esta', 'nosso', 'estes', 'houverão', 'delas', 'mais', 'nas', 'houveria', 'sejam', 'estejam', 'seremos', 'somos', 'que', 'para', 'dela', 'houvessem', 'teus', 'houverei', 'são', 'estivessem', 'sua', 'estivera', 'ela', 'sejamos', 'eu', 'houveram', 'terão', 'hei', 'há', 'quando', 'numa', 'qual', 'houver', 'tiver', 'uma', 'houve', 'fui', 'tivera', 'depois', 'estivesse', 'éramos', 'tinham', 'às', 'estive', 'nem', 'estão', 'a', 'muito', 'o', 'serei', 'dele', 'ou', 'me', 'este', 'teve', 'as', 'nós', 'mesmo', 'estamos', 'aquela', 'houveremos', 'fosse', 'era', 'tenhamos', 'terei', 'teríamos', 'das', 'seríamos', 'hão', 'elas', 'serão', 'tenho', 'da', 'te', 'isto', 'houverá', 'tenha', 'no', 'nos', 'estou', 'estas', 'estávamos', 'aquelas', 'seus', 'de', 'teremos', 'seja', 'à', 'houvéramos', 'esses', 'será', 'tiveram', 'estivéramos', 'teu', 'tivemos', 'meu', 'foram', 'vocês', 'terá', 'estiveram', 'vos', 'nossa', 'é', 'num', 'estivemos', 'houvera', 'fora', 'por', 'teriam', 'fomos', 'nossas', 'eles', 'hajam', 'estava', 'aquele', 'com', 'houvesse', 'temos', 'ele', 'esteja', 'tiverem', 'houveríamos', 'sem', 'esteve', 'ao', 'fôramos', 'do', 'aquilo', 'fossem', 'na', 'lhes', 'tenham', 'estejamos', 'pelas'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWCAAwaPuuH_",
        "outputId": "9865fa82-96b3-4756-d2fe-95d12b1f735e"
      },
      "source": [
        "import string\n",
        "from nltk.tokenize.regexp import RegexpTokenizer\n",
        "\n",
        "def preprocess(text):\n",
        "  \n",
        "  # remover pontuações\n",
        "  text   = text.translate(string.punctuation)\n",
        "  \n",
        "  # converter para lowercase\n",
        "  text = text.lower()\n",
        "  \n",
        "  # tokenizar o texto em palavras\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(text.lower())\n",
        "\n",
        "  # filtrar palavras\n",
        "  tokens = [word for word in tokens\n",
        "            if word not in stop_words       # descartar stopwords\n",
        "                and len(word) > 3          # descartar palavras com menos de 3 caracteres\n",
        "                and not word[0].isdigit()] # descartar tokens contendo apenas numeros\n",
        "\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "majority_pos = []\n",
        "for doc in majority['txt']:\n",
        "#for doc in majority['objeto']:\n",
        "  majority_pos.append(preprocess(doc))\n",
        "\n",
        "print(majority_pos[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatos joão césar sala eldorado contagem marques medeiros advogados requerente viajou trabalho cidade corumbá realização acompanhamento perícia determinada processo judicial desembarcar esteira verificando após alguns minutos bagagem encontrava dirigindo recepção companhia aérea sendo informado encontrava campinas local onde escala solicitado césar augusto preenche formulário após informado bagagem poderia retirada contudo referida data requerido passagem comprada retorno além precisar equipamentos segurança obrigatório acompanhamento perícia tais colete segurança botina uniforme dentre outros funcionário azul elton solicitou autor realiza compra roupas pessoal higiene valor reembolsado apresentação respectivo comprovante contudo tais objetos equipamentos necessários realização trabalho realizada reembolso parcialmente realizado césar verificou havia vindo curitiba cidade próxima corumbá podendo empresa levar utilizando carro possibilitaria realiza trabalho maiores problemas contudo elton informou poderia feito joão césar sala eldorado contagem marques medeiros advogados objetos pessoais equipamentos trabalho estando cidade desconhecia césar augusto alternativa entrar contato empresa contratante solicitar ajuda obtenção equipamentos realização serviço seguinte danos materiais dito requerente sofreu prejuízos materiais decorrência extravio mala parte requerido fazendo ressarcimento valor todos objetos comprar permanecer comarca corumbá valor gasto quatrocentos dezenove reais noventa cinco centavos sendo reembolsado importe cento cinquenta reais ficando saldo remanescente duzentos sessenta nove reais noventa cinco centavos dano moral requerente sofreu danos morais culpa requerida cometido assinala dano moral consiste agressão íntimo produzindo dolorosa sensação perda valores tranquilidade dignidade prestígio social comercial familiar tendo vista todo dano impõe dever reparar invariavelmente divorcia desse princípio geral norma expressa civil joão césar sala eldorado contagem marques medeiros advogados outra parte cabe destacar direito positivo nunca negou ressarcimento dano extrapatrimonial desfazer quaisquer dúvidas ensina maria helena diniz reparação dano moral juiz determina equidade levando conta circunstâncias cada caso quantum indenização devida deverá corresponder lesão equivalente impossível equivalência reparação pecuniária dano moral misto pena satisfação compensatória pode negar função penal constituindo sanção imposta ofensor compensatória sendo satisfação atenue ofensa causada proporcionando vantagem ofendido poderá soma dinheiro recebida procurar atender necessidades materiais ideais repute convenientes diminuindo assim sofrimento assim constituição federal agasalhando posição seguida outros países admitiu assegurou indenização dano puramente moral inciso verbis invioláveis intimidade vida privada honra imagem pessoas assegurado direito indenização dano material moral decorrente violação guisa situação mencionada alhures resta evidente requerente sofrendo constrangimentos aborrecimentos razão procedimento requerida passíveis serem ressarcidos meio indenização joão césar sala eldorado contagem remo marques medeiros advogados entendimento tjmg ementa dano moral puro caracterização sobrevindo razão ilícito perturbação relações psíquicas tranquilidade sentimentos afetos pessoa configura dano moral passível indenização recurso especial conhecido provido grifos sentido egrégia corte superior tribunal justiça entende ementa dano moral puro caracterização sobrevindo razão ilícito perturbação relações psíquicas tranquilidade entendimentos afetos pessoa configura dano moral passível indenização barros monteiro resp decisão requerente ficou usufruir bens pessoais comprados esforço culpa requerido além informar cliente quanto impossibilidade realização serviço contratado caso fornecesse equipamentos necessários caso cliente conseguisse fornecer tais equipamentos perito realizaria trabalhos devido acompanhamento assistente técnico indicado partes poderia atrapalhar alegações mesma último caso realizada novamente atrasando ainda moroso processo judicial joão césar sala eldorado contagem remo marques medeiros advogados tratando caso tela meros dissabores vida cotidiana culpa requerido causou inúmeros transtornos vida profissional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1jNcZ-WN5sa"
      },
      "source": [
        "Em seguida, utilize as funções de transformação do Scikit-Learn para textos, utilizando os atributos de n-gramas para classificar os textos:\n",
        "```\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(use_idf=True)\n",
        "```\n",
        "No qual você pode passar os valores de intervalos de n-gramas:\n",
        "- um intervalo de ngram de (1, 1) significa apenas unigramas\n",
        "- (1, 2) significa unigramas e bigrams \n",
        "- (2, 2) significa apenas bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4RF0P1GN-jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b505046e-06a2-4e46-c303-7709cc75fe26"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), )\n",
        "tfidf_model = vectorizer.fit(majority_pos)\n",
        "\n",
        "X_tfidf = tfidf_model.transform(majority_pos)\n",
        "\n",
        "print(X_tfidf[0,:])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 148847)\t0.03129658397757183\n",
            "  (0, 148840)\t0.018311708787398028\n",
            "  (0, 148570)\t0.03129658397757183\n",
            "  (0, 148563)\t0.021673571742059312\n",
            "  (0, 146253)\t0.02921207112437228\n",
            "  (0, 146099)\t0.010204725133254988\n",
            "  (0, 145761)\t0.03129658397757183\n",
            "  (0, 145735)\t0.013642314048228046\n",
            "  (0, 145572)\t0.03129658397757183\n",
            "  (0, 145562)\t0.02029441551646866\n",
            "  (0, 145269)\t0.03129658397757183\n",
            "  (0, 145268)\t0.01704259093952433\n",
            "  (0, 145245)\t0.02921207112437228\n",
            "  (0, 145233)\t0.039277097901506935\n",
            "  (0, 145182)\t0.02921207112437228\n",
            "  (0, 145168)\t0.02029441551646866\n",
            "  (0, 144055)\t0.025648572864860403\n",
            "  (0, 144045)\t0.019458898993217115\n",
            "  (0, 143977)\t0.03129658397757183\n",
            "  (0, 143976)\t0.023022397252728994\n",
            "  (0, 143765)\t0.03129658397757183\n",
            "  (0, 143748)\t0.01688439257245792\n",
            "  (0, 143056)\t0.03129658397757183\n",
            "  (0, 143052)\t0.02485607785849934\n",
            "  (0, 143019)\t0.03129658397757183\n",
            "  :\t:\n",
            "  (0, 6260)\t0.03129658397757183\n",
            "  (0, 6237)\t0.017729081339475587\n",
            "  (0, 5926)\t0.03129658397757183\n",
            "  (0, 5912)\t0.02000056175214897\n",
            "  (0, 5657)\t0.03129658397757183\n",
            "  (0, 5431)\t0.007107905021444259\n",
            "  (0, 5063)\t0.03129658397757183\n",
            "  (0, 5060)\t0.026585895512240866\n",
            "  (0, 4698)\t0.03129658397757183\n",
            "  (0, 4697)\t0.03129658397757183\n",
            "  (0, 4485)\t0.06259316795514366\n",
            "  (0, 4482)\t0.05546617143611992\n",
            "  (0, 3503)\t0.03129658397757183\n",
            "  (0, 3498)\t0.02921207112437228\n",
            "  (0, 3488)\t0.03129658397757183\n",
            "  (0, 3484)\t0.03129658397757183\n",
            "  (0, 3472)\t0.03129658397757183\n",
            "  (0, 3446)\t0.07479039043162387\n",
            "  (0, 2738)\t0.03129658397757183\n",
            "  (0, 2737)\t0.02921207112437228\n",
            "  (0, 1565)\t0.06259316795514366\n",
            "  (0, 1561)\t0.03129658397757183\n",
            "  (0, 1560)\t0.07250876237564424\n",
            "  (0, 438)\t0.03129658397757183\n",
            "  (0, 404)\t0.016296204235656662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvhV-u3N_2Wo"
      },
      "source": [
        "Separe o conjunto em treino e teste. Utilize a função `sklearn.model_selection.train_test_split()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpg1zl1gAHlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8501f0-5cd1-46b7-e879-abeab766cfa1"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "X_train = sklearn.model_selection.train_test_split(majority_pos)[0]\n",
        "X_test = sklearn.model_selection.train_test_split(majority_pos)[1]\n",
        "\n",
        "X_tfidf_train = tfidf_model.transform(X_train)\n",
        "X_tfidf_test  = tfidf_model.transform(X_test)\n",
        "\n",
        "print(X_tfidf_train[0,:])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 148921)\t0.036455078541315314\n",
            "  (0, 148908)\t0.017024867151528598\n",
            "  (0, 148749)\t0.03905643739260093\n",
            "  (0, 148650)\t0.01643222391505718\n",
            "  (0, 148623)\t0.036455078541315314\n",
            "  (0, 148616)\t0.024283649321030287\n",
            "  (0, 148128)\t0.036455078541315314\n",
            "  (0, 148115)\t0.025326328573316827\n",
            "  (0, 147089)\t0.03101903547690041\n",
            "  (0, 147047)\t0.011146183738217599\n",
            "  (0, 146754)\t0.03905643739260093\n",
            "  (0, 146690)\t0.01004581600169488\n",
            "  (0, 145355)\t0.036455078541315314\n",
            "  (0, 145352)\t0.03317775397928993\n",
            "  (0, 144421)\t0.03905643739260093\n",
            "  (0, 144355)\t0.007609274222839606\n",
            "  (0, 144153)\t0.036455078541315314\n",
            "  (0, 144152)\t0.02756097388305566\n",
            "  (0, 143329)\t0.036455078541315314\n",
            "  (0, 143309)\t0.01652727365859627\n",
            "  (0, 142260)\t0.036455078541315314\n",
            "  (0, 142250)\t0.0246127337790968\n",
            "  (0, 142216)\t0.036455078541315314\n",
            "  (0, 142210)\t0.027047440654366903\n",
            "  (0, 142026)\t0.036455078541315314\n",
            "  :\t:\n",
            "  (0, 4732)\t0.03460938506347111\n",
            "  (0, 4718)\t0.024959615031770035\n",
            "  (0, 4675)\t0.060324665468682565\n",
            "  (0, 4674)\t0.05881333472179972\n",
            "  (0, 4311)\t0.036455078541315314\n",
            "  (0, 4303)\t0.020165681449966975\n",
            "  (0, 4252)\t0.03905643739260093\n",
            "  (0, 4238)\t0.03905643739260093\n",
            "  (0, 4144)\t0.03905643739260093\n",
            "  (0, 3987)\t0.041758552488374\n",
            "  (0, 3927)\t0.03792734054456883\n",
            "  (0, 3634)\t0.03460938506347111\n",
            "  (0, 3609)\t0.012274652582796256\n",
            "  (0, 3434)\t0.03905643739260093\n",
            "  (0, 3369)\t0.018939920659954528\n",
            "  (0, 3341)\t0.03905643739260093\n",
            "  (0, 3324)\t0.023970624296484964\n",
            "  (0, 1517)\t0.03905643739260093\n",
            "  (0, 1513)\t0.028730701650160114\n",
            "  (0, 1257)\t0.036455078541315314\n",
            "  (0, 1231)\t0.013894074839520447\n",
            "  (0, 841)\t0.036455078541315314\n",
            "  (0, 839)\t0.026571983147770584\n",
            "  (0, 528)\t0.036455078541315314\n",
            "  (0, 526)\t0.030162332734341282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuh4HvH9AH03"
      },
      "source": [
        "Treine um modelo com o algoritmo `NaiveBayes`, e salve as predições para o conjunto de testes na variável `preds`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sirb-mtbAR7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90719e4-dbf5-49ab-da37-4b66732e9a3a"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "\n",
        "majority_train = sklearn.model_selection.train_test_split(majority)[0]\n",
        "majority_test = sklearn.model_selection.train_test_split(majority)[1]\n",
        "\n",
        "clf.fit(X_tfidf_train, majority_train.label)\n",
        "\n",
        "acc = clf.score(X_tfidf_test , majority_test.label)\n",
        "print('Acurácia: ', acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia:  0.5061728395061729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S89512TgtYq5",
        "outputId": "9fdc4221-3fd0-496c-cc74-9e245fb477ac"
      },
      "source": [
        "preds = clf.predict(X_tfidf_test)\n",
        "preds"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AExPjo0p_vjJ"
      },
      "source": [
        "Analise os resultados das predições"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwO2v9gmAYuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e5be4f-80c4-46eb-da6e-886842c783d0"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(majority_test.label, preds))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        14\n",
            "           1       0.51      1.00      0.68        41\n",
            "           2       0.00      0.00      0.00        15\n",
            "           3       0.00      0.00      0.00        11\n",
            "\n",
            "    accuracy                           0.51        81\n",
            "   macro avg       0.13      0.25      0.17        81\n",
            "weighted avg       0.26      0.51      0.34        81\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYI7pPVhGBxJ"
      },
      "source": [
        "## BOW + NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQHgbZC7GD5e",
        "outputId": "07b12171-fe38-4641-d915-98b3d33ea03c"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "Bow_model = vectorizer.fit(majority_pos)\n",
        "\n",
        "X_bow = Bow_model.transform(majority_pos)\n",
        "\n",
        "print(X_bow[0,:])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 404)\t1\n",
            "  (0, 438)\t1\n",
            "  (0, 1560)\t3\n",
            "  (0, 1561)\t1\n",
            "  (0, 1565)\t2\n",
            "  (0, 2737)\t1\n",
            "  (0, 2738)\t1\n",
            "  (0, 3446)\t5\n",
            "  (0, 3472)\t1\n",
            "  (0, 3484)\t1\n",
            "  (0, 3488)\t1\n",
            "  (0, 3498)\t1\n",
            "  (0, 3503)\t1\n",
            "  (0, 4482)\t2\n",
            "  (0, 4485)\t2\n",
            "  (0, 4697)\t1\n",
            "  (0, 4698)\t1\n",
            "  (0, 5060)\t1\n",
            "  (0, 5063)\t1\n",
            "  (0, 5431)\t1\n",
            "  (0, 5657)\t1\n",
            "  (0, 5912)\t1\n",
            "  (0, 5926)\t1\n",
            "  (0, 6237)\t1\n",
            "  (0, 6260)\t1\n",
            "  :\t:\n",
            "  (0, 143019)\t1\n",
            "  (0, 143052)\t1\n",
            "  (0, 143056)\t1\n",
            "  (0, 143748)\t1\n",
            "  (0, 143765)\t1\n",
            "  (0, 143976)\t1\n",
            "  (0, 143977)\t1\n",
            "  (0, 144045)\t1\n",
            "  (0, 144055)\t1\n",
            "  (0, 145168)\t1\n",
            "  (0, 145182)\t1\n",
            "  (0, 145233)\t3\n",
            "  (0, 145245)\t1\n",
            "  (0, 145268)\t1\n",
            "  (0, 145269)\t1\n",
            "  (0, 145562)\t1\n",
            "  (0, 145572)\t1\n",
            "  (0, 145735)\t1\n",
            "  (0, 145761)\t1\n",
            "  (0, 146099)\t1\n",
            "  (0, 146253)\t1\n",
            "  (0, 148563)\t1\n",
            "  (0, 148570)\t1\n",
            "  (0, 148840)\t1\n",
            "  (0, 148847)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqSvOTu7GHQW",
        "outputId": "64355f0a-7a35-48a1-8e0d-dd817dbc1c42"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "X_train = sklearn.model_selection.train_test_split(majority_pos)[0]\n",
        "X_test = sklearn.model_selection.train_test_split(majority_pos)[1]\n",
        "\n",
        "X_bow_train = Bow_model.transform(X_train)\n",
        "X_bow_test  = Bow_model.transform(X_test)\n",
        "\n",
        "print(X_bow_train[0,:])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 249)\t1\n",
            "  (0, 251)\t1\n",
            "  (0, 826)\t1\n",
            "  (0, 833)\t1\n",
            "  (0, 1595)\t1\n",
            "  (0, 1604)\t1\n",
            "  (0, 1616)\t1\n",
            "  (0, 1618)\t1\n",
            "  (0, 2282)\t1\n",
            "  (0, 2356)\t1\n",
            "  (0, 2934)\t1\n",
            "  (0, 2945)\t1\n",
            "  (0, 3179)\t1\n",
            "  (0, 3194)\t1\n",
            "  (0, 4459)\t1\n",
            "  (0, 4460)\t1\n",
            "  (0, 5431)\t1\n",
            "  (0, 5659)\t1\n",
            "  (0, 6495)\t1\n",
            "  (0, 6546)\t1\n",
            "  (0, 6661)\t1\n",
            "  (0, 6665)\t1\n",
            "  (0, 7393)\t1\n",
            "  (0, 7443)\t1\n",
            "  (0, 7674)\t1\n",
            "  :\t:\n",
            "  (0, 144691)\t1\n",
            "  (0, 145016)\t1\n",
            "  (0, 145086)\t1\n",
            "  (0, 145233)\t1\n",
            "  (0, 145264)\t1\n",
            "  (0, 145611)\t3\n",
            "  (0, 145621)\t2\n",
            "  (0, 145627)\t1\n",
            "  (0, 145906)\t1\n",
            "  (0, 145933)\t1\n",
            "  (0, 146099)\t1\n",
            "  (0, 146246)\t1\n",
            "  (0, 146690)\t1\n",
            "  (0, 146875)\t1\n",
            "  (0, 147488)\t1\n",
            "  (0, 147489)\t1\n",
            "  (0, 147764)\t1\n",
            "  (0, 147765)\t1\n",
            "  (0, 147935)\t2\n",
            "  (0, 147936)\t1\n",
            "  (0, 147937)\t1\n",
            "  (0, 148584)\t1\n",
            "  (0, 148585)\t1\n",
            "  (0, 148908)\t1\n",
            "  (0, 148917)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfFqJWZQGNd2",
        "outputId": "4ab81ea3-e882-4923-d00c-7be71d7fac33"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()\n",
        "\n",
        "majority_train = sklearn.model_selection.train_test_split(majority)[0]\n",
        "majority_test = sklearn.model_selection.train_test_split(majority)[1]\n",
        "\n",
        "#clf.fit(X_tfidf_train, majority_train.label)\n",
        "\n",
        "#acc = clf.score(X_tfidf_test , majority_test.label)\n",
        "#print('Acurácia: ', acc)\n",
        "\n",
        "clf.fit(X_bow_train, majority_train.label)\n",
        "\n",
        "acc = clf.score(X_bow_test , majority_test.label)\n",
        "print('Acurácia: ', acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia:  0.2839506172839506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MefGcT3KgyE",
        "outputId": "bb24b63a-6efe-4906-8cb9-a5f9689ec74a"
      },
      "source": [
        "preds = clf.predict(X_bow_test)\n",
        "preds"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 1, 1, 3, 1, 1, 2, 0, 1, 0, 3, 0, 2, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 3, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1, 2, 0, 0, 3, 1,\n",
              "       1, 1, 3, 0, 1, 0, 0, 1, 3, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 3,\n",
              "       1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lElm3jlRKwUZ",
        "outputId": "ae3591a6-4fc7-4424-f00c-54f0870e92b1"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(majority_test.label, preds))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.16      0.15        19\n",
            "           1       0.36      0.49      0.41        35\n",
            "           2       0.60      0.14      0.23        21\n",
            "           3       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.28        81\n",
            "   macro avg       0.27      0.20      0.20        81\n",
            "weighted avg       0.34      0.28      0.27        81\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp25T82nBDgo"
      },
      "source": [
        "Discuta os resultados. Qual foi a melhor abordagem? Qual foi a pior? Porque você acha que esses resultados foram o melhor e o pior? Algum resultado chamou sua atenção, porque?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoCJn3sbLcfb"
      },
      "source": [
        "####Ambas tiveram uma acurácia baixa, apesar do IF-IDF ter um resultado maior. Entranto, o desbalanceamento parece ter maior influência sobre ele pois, quase a totalidade das classificações são para o rótulo mais frequente. Enquanto isso, Bag of Words também classifica outros rótulos, por mais que estejam errados com mais frequência que a primeira técnica. Assim, melhor ou pior dependerá da aplicação, se a ideia é focar nos atrasos e cancelamentos a primeira é mais coerente, mas se a busca é para tentar realmente diversificar para passar para o departamento responsável, por exemplo, a segunda parece mais coerente. Contudo, vale tentar melhorar a acurácia antes de sua aplicação final."
      ]
    }
  ]
}