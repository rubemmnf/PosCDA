{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommender Systems Lab: Crash Course AI #16",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwQKpt7BtidS"
      },
      "source": [
        "Recommender Systems are a class of AI systems that predict and recommend new items (e.g. YouTube videos, Netflix shows, Amazon products).\n",
        "\n",
        "In this lab, we'll use recommender systems to try to find a good movie for our next movie night!\n",
        "\n",
        "Here's what we need to do:\n",
        "* Step 1: Get a dataset of movie ratings, and make sure we understand how the dataset is structured.\n",
        "* Step 2: Try to get just a non-personalized set of recommendations for John-Green-bot and me, to see if we can find a movie to watch that way.\n",
        "* Step 3: Get personalized ratings for John-Green-bot and me, and import them into the system in the correct format.\n",
        "* Step 4: Train a User-User collaborative filtering model to provide personalized recommendations based on John-Green-bot's and my prior ratings.\n",
        "* Step 5: Combine ratings to generate a single ranked recommendation list for our movie night together!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgF-tyNsvFAs"
      },
      "source": [
        "\n",
        "Just like in our other labs, we're not going to reinvent the wheel from scratch. We'll use an existing dataset published by MovieLens, which contains about 100,000 user ratings for about 10,000 different movies. You can read more about this dataset here: http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html\n",
        "\n",
        "We'll also use the LensKit API to implement our recommender systems algorithms.\n",
        "\n",
        "***STEP 1***\n",
        "\n",
        "**Step 1.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDDl3BSpW6yn"
      },
      "source": [
        "!pip install lenskit\n",
        "\n",
        "import lenskit.datasets as ds\n",
        "import pandas as pd\n",
        "\n",
        "!git clone https://github.com/crash-course-ai/lab4-recommender-systems.git\n",
        "\n",
        "data = ds.MovieLens('lab4-recommender-systems/')\n",
        "\n",
        "print(\"Successfully installed dataset.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr0KflfewGmK"
      },
      "source": [
        "It's important to understand how a dataset is structured and to make sure that the dataset imported correctly.  Let's print out a few rows of the rating data. \n",
        "\n",
        "As you see, MovieLens stores a user's ID number (the first row few rows look like they're all ratings from user 1), the item's ID (in this case each ID is a different movie), the rating the user gave this item, and a time stamp for when the rating was left.\n",
        "\n",
        "**Step 1.2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDMkG60jwi1e"
      },
      "source": [
        "rows_to_show = 10   # <-- Try changing this number to see more rows of data\n",
        "data.ratings.head(rows_to_show)  # <-- Try changing \"ratings\" to \"movies\", \"tags\", or \"links\" to see the kinds of data that's stored in the other MovieLens files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vInLs2Qpvj2N"
      },
      "source": [
        "A big aspect of recommender system datasets is how they handle missing data. Recommender systems usually have a LOT of missing data, because most users only rate a few movies and most movies only receive ratings from a few users. \n",
        "\n",
        "For example, we can see that user #1 provided rating of 4.0 to the item #1 and that they provided a rating of 4.0 to item #3. But there isn't a rating for item #2 at all, which means that user #1 never rated this item. It's helpful to know that this dataset doesn't store unranked items at all, instead of, for example, storing unranked items as 0 ratings. \n",
        "\n",
        "But here we have another small issue: names like item #1 and item #2 aren't very descriptive, so we can't tell what those movies are. Thankfully, MovieLens also has a data table called \"movies\" that includes information about titles and genres. We can get a more meaningful look at these data by joining the two data files. \n",
        "\n",
        "**Step 1.3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdHdpVcs_Uut"
      },
      "source": [
        "joined_data = data.ratings.join(data.movies['genres'], on='item')\n",
        "joined_data = joined_data.join(data.movies['title'], on='item')\n",
        "joined_data.head(rows_to_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaitUo64yJWn"
      },
      "source": [
        "Now we can see the titles and genres of each item, and we'll continue using \"join\" before printing results in other parts of the lab as well.\n",
        "\n",
        "Because we've successfully imported our ratings data and see how it's structured, we're done with Step 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtzfC8usynQp"
      },
      "source": [
        "***STEP 2***\n",
        "\n",
        "Now that we have ratings, let's create a generic set of recommended movies by looking at the highest rated films. We can average all the ratings by item, sort the list in descending order, and print that top set of recommendations.\n",
        "\n",
        "**Step 2.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGm49VPv-6VA"
      },
      "source": [
        "average_ratings = (data.ratings).groupby(['item']).mean()\n",
        "sorted_avg_ratings = average_ratings.sort_values(by=\"rating\", ascending=False)\n",
        "joined_data = sorted_avg_ratings.join(data.movies['genres'], on='item')\n",
        "joined_data = joined_data.join(data.movies['title'], on='item')\n",
        "joined_data = joined_data[joined_data.columns[1:]]\n",
        "\n",
        "print(\"RECOMMENDED FOR ANYBODY:\")\n",
        "joined_data.head(rows_to_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIbDfSCiESbG"
      },
      "source": [
        "That seemed like a good idea, but the results are strange... _Paper Birds_? _Bill Hicks: Revelations_? Those are pretty obscure movies. Let's see what's actually happening here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDg7Y0dQEeMM"
      },
      "source": [
        "average_ratings = (data.ratings).groupby('item') \\\n",
        "       .agg(count=('user', 'size'), rating=('rating', 'mean')) \\\n",
        "       .reset_index()\n",
        "\n",
        "sorted_avg_ratings = average_ratings.sort_values(by=\"rating\", ascending=False)\n",
        "joined_data = sorted_avg_ratings.join(data.movies['genres'], on='item')\n",
        "joined_data = joined_data.join(data.movies['title'], on='item')\n",
        "joined_data = joined_data[joined_data.columns[1:]]\n",
        "\n",
        "\n",
        "print(\"RECOMMENDED FOR ANYBODY:\")\n",
        "joined_data.head(rows_to_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8W9h1xIzLRB"
      },
      "source": [
        "Adding the \"count\" column, we can see that each of these movies was given a perfect 5.0 rating but by just ONE person. They might be good movies, but we can't be very confident in these recommendations.\n",
        "\n",
        "To improve this list, we should try only including movies in this recommendation list if they have more than a certain number of ratings, so we can be more confident that each movie is generally good. Let's start with movies that 20 or more people rated.\n",
        "\n",
        "**Step 2.2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTDrKYWAwP1"
      },
      "source": [
        "minimum_to_include = 20 #<-- You can try changing this minimum to include movies rated by fewer or more people\n",
        "\n",
        "average_ratings = (data.ratings).groupby(['item']).mean()\n",
        "rating_counts = (data.ratings).groupby(['item']).count()\n",
        "average_ratings = average_ratings.loc[rating_counts['rating'] > minimum_to_include]\n",
        "sorted_avg_ratings = average_ratings.sort_values(by=\"rating\", ascending=False)\n",
        "joined_data = sorted_avg_ratings.join(data.movies['genres'], on='item')\n",
        "joined_data = joined_data.join(data.movies['title'], on='item')\n",
        "joined_data = joined_data[joined_data.columns[3:]]\n",
        "\n",
        "print(\"RECOMMENDED FOR ANYBODY:\")\n",
        "joined_data.head(rows_to_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2x1SVa38RhJ"
      },
      "source": [
        "These movies are more commonly known and we can trust that they're more popularly recommended. But these movies span a bunch of genres, so we can try narrowing the list down a bit more.\n",
        "\n",
        "Let's try to get a list of recommendations from John-Green-bot's and my favorite genres. I like Action movies and he prefers Romance movies. So in addition to filtering by the number of ratings, let's also filter by a particular genre. We'll run the recommendations for an action movie fan, then for a romance movie fan.\n",
        "\n",
        "**Step 2.3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU97FBThZn3B"
      },
      "source": [
        "average_ratings = (data.ratings).groupby(['item']).mean()\n",
        "rating_counts = (data.ratings).groupby(['item']).count()\n",
        "average_ratings = average_ratings.loc[rating_counts['rating'] > minimum_to_include]\n",
        "average_ratings = average_ratings.join(data.movies['genres'], on='item')\n",
        "average_ratings = average_ratings.loc[average_ratings['genres'].str.contains('Action')]\n",
        "\n",
        "sorted_avg_ratings = average_ratings.sort_values(by=\"rating\", ascending=False)\n",
        "joined_data = sorted_avg_ratings.join(data.movies['title'], on='item')\n",
        "joined_data = joined_data[joined_data.columns[3:]]\n",
        "print(\"RECOMMENDED FOR AN ACTION MOVIE FAN:\")\n",
        "joined_data.head(rows_to_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLE4QrmZmHz4"
      },
      "source": [
        "average_ratings = (data.ratings).groupby(['item']).mean()\n",
        "rating_counts = (data.ratings).groupby(['item']).count()\n",
        "average_ratings = average_ratings.loc[rating_counts['rating'] > minimum_to_include]\n",
        "average_ratings = average_ratings.join(data.movies['genres'], on='item')\n",
        "average_ratings = average_ratings.loc[average_ratings['genres'].str.contains('Romance')]\n",
        "\n",
        "sorted_avg_ratings = average_ratings.sort_values(by=\"rating\", ascending=False)\n",
        "joined_data = sorted_avg_ratings.join(data.movies['title'], on='item')\n",
        "joined_data = joined_data[joined_data.columns[3:]]\n",
        "print(\"RECOMMENDED FOR A ROMANCE MOVIE FAN:\")\n",
        "joined_data.head(rows_to_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em-XbUsP9WfX"
      },
      "source": [
        "There's actually one movie that's on both of these lists: _The Princess Bride_. But John-Green-bot doesn't want to rewatch.\n",
        "\n",
        "So, while Step 2 produced some generic recommendations, our AI hasn't given us a new movie we want to watch together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETrwA7hW-NhV"
      },
      "source": [
        "***STEP 3***\n",
        "\n",
        "Step 3 is personalizing our recommender system AI. John-Green-bot and I each need to provide our own movie ratings as data, so we filled out simple spreadsheets. We've uploaded these spreadsheets to GitHub. Here's mine, for example: https://github.com/crash-course-ai/lab4-recommender-systems/blob/master/jabril-movie-ratings.csv\n",
        "\n",
        "But, we need to provide these personalized ratings in the correct format. By looking at the documentation for LensKit (https://lkpy.lenskit.org/en/stable/interfaces.html#lenskit.algorithms.Recommender.recommend), we know that we need to provide a dictionary of item-rating pairs for each person. This means that we need to import the two spreadsheets from GitHub and format the data in a way that will make sense to our AI: two dictionaries.\n",
        "\n",
        "To test that it worked, let's also print both our ratings for _The Princess Bride_, since we know that's a movie we both watched.\n",
        "\n",
        "**Step 3.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM3cgXCMbVqs"
      },
      "source": [
        "import csv\n",
        "\n",
        "jabril_rating_dict = {}\n",
        "jgb_rating_dict = {}\n",
        "\n",
        "with open(\"/content/lab4-recommender-systems/jabril-movie-ratings.csv\", newline='') as csvfile:\n",
        "  ratings_reader = csv.DictReader(csvfile)\n",
        "  for row in ratings_reader:\n",
        "    if ((row['ratings'] != \"\") and (float(row['ratings']) > 0) and (float(row['ratings']) < 6)):\n",
        "      jabril_rating_dict.update({int(row['item']): float(row['ratings'])})\n",
        "      \n",
        "with open(\"/content/lab4-recommender-systems/jgb-movie-ratings.csv\", newline='') as csvfile:\n",
        "  ratings_reader = csv.DictReader(csvfile)\n",
        "  for row in ratings_reader:\n",
        "    if ((row['ratings'] != \"\") and (float(row['ratings']) > 0) and (float(row['ratings']) < 6)):\n",
        "      jgb_rating_dict.update({int(row['item']): float(row['ratings'])})\n",
        "     \n",
        "print(\"Rating dictionaries assembled!\")\n",
        "print(\"Sanity check:\")\n",
        "print(\"\\tJabril's rating for 1197 (The Princess Bride) is \" + str(jabril_rating_dict[1197]))\n",
        "print(\"\\tJohn-Green-Bot's rating for 1197 (The Princess Bride) is \" + str(jgb_rating_dict[1197]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipyWOFAMADaa"
      },
      "source": [
        "***STEP 4***\n",
        "\n",
        "In Step 4, we want to actually train a new collaborative filtering model to provide recommendations. We'll use the UserUser library from LensKit to do this. This algorithm clusters similar users based on their movie ratings, and uses those clusters to predict movie ratings for one user (in this case, we'll want that user to be John-Green-bot or myself).\n",
        "\n",
        "We're guiding how the algorithm decides whether a particular group of users should be clustered together by setting a minimum and maximum neighborhood size. These parameters modify the result of the algorithm.\n",
        "\n",
        "Really small clusters represent groups of people who aren't very similar to a lot of others. So by keeping cluster size small, we'll see more unconventional recommendations. But increasing our minimum cluster size, will probably give more conventionally popular recommendations. \n",
        "\n",
        "Right now, we set the minimum to 3 and the maximum to 15, so the algorithm won't define a cluster unless it has at least 3 users, and it will use the 15 closest users (at most) to make rating predictions. The values we've chosen are considered reasonable defaults, and the \"best\" values depend on what we want from the recommender system AI. Do they want to be surprised by recommendations they wouldn't otherwise know about? Or are they looking for a more confident expression of quality? \n",
        "\n",
        "**Step 4.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCpGlQwpKTp5"
      },
      "source": [
        "from lenskit.algorithms import Recommender\n",
        "from lenskit.algorithms.user_knn import UserUser\n",
        "\n",
        "num_recs = 10  #<---- This is the number of recommendations to generate. You can change this if you want to see more recommendations\n",
        "\n",
        "user_user = UserUser(15, min_nbrs=3) #These two numbers set the minimum (3) and maximum (15) number of neighbors to consider. These are considered \"reasonable defaults,\" but you can experiment with others too\n",
        "algo = Recommender.adapt(user_user)\n",
        "algo.fit(data.ratings)\n",
        "\n",
        "print(\"Set up a User-User algorithm!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLQt0bs4DE8k"
      },
      "source": [
        "Now that the system has defined clusters, we can give it our personal ratings to get the top 10 recommended movies for me and for John-Green-bot!\n",
        "\n",
        "For each of us, the User-User algorithm will find a neighborhood of users similar to us based on their movie ratings. It will look at movies that these similar users have rated that we haven't seen yet. Based on their ratings, it will predict how we may rate that movie if we watched it. Finally, it will order these predictions and print them in descending order to give our \"top 10.\"\n",
        "\n",
        "**Step 4.2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhJjyTcZmYdC"
      },
      "source": [
        "jabril_recs = algo.recommend(-1, num_recs, ratings=pd.Series(jabril_rating_dict))  #Here, -1 tells it that it's not an existing user in the set, that we're giving new ratings, while 10 is how many recommendations it should generate\n",
        "\n",
        "joined_data = jabril_recs.join(data.movies['genres'], on='item')      \n",
        "joined_data = joined_data.join(data.movies['title'], on='item')\n",
        "joined_data = joined_data[joined_data.columns[2:]]\n",
        "print(\"\\n\\nRECOMMENDED FOR JABRIL:\")\n",
        "joined_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2TIloetmeuB"
      },
      "source": [
        "jgb_recs = algo.recommend(-1, num_recs, ratings=pd.Series(jgb_rating_dict))  #Here, -1 tells it that it's not an existing user in the set, that we're giving new ratings, while 10 is how many recommendations it should generate\n",
        "\n",
        "joined_data = jgb_recs.join(data.movies['genres'], on='item')      \n",
        "joined_data = joined_data.join(data.movies['title'], on='item')\n",
        "joined_data = joined_data[joined_data.columns[2:]]\n",
        "print(\"RECOMMENDED FOR JOHN-GREEN-BOT:\")\n",
        "joined_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHtgnyRpDfww"
      },
      "source": [
        "Now, we have \"top 10\" lists of movies for both John-Green-bot and myself! Each of these only has movies that each of us hasn't watched before (or at least that we didn't rate in our personal ratings). These lists include both popular movies and more obscure ones.\n",
        "\n",
        "That concludes Step 4 of getting personalized recommendations, but our lists don't overlap at all, so we still haven't found a movie for both of us to watch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR5t0Bd8F22h"
      },
      "source": [
        "***STEP 5***\n",
        "\n",
        "That brings us to Step 5, making a combined movie recommendation list. Because rating preferences are stored as numbers, we can create a Jabril/John-Green-bot hybrid!\n",
        "\n",
        "We'll do this by creating a combined dictionary of ratings. If both of us have rated a movie, it will average our ratings. If only one of us has rated a movie, it will just add that movie to the list of preferences. This isn't a perfect strategy; it's possible that I would have hated some movie that I've never seen but John-Green-bot rated highly. But we should get a reasonable estimate across both of our datasets.\n",
        "\n",
        "We'll also do a quick sanity check by looking at _The Princess Bride_ again. I rated it as a 4.5 (because it's awesome!!) and John-Green-bot rated it as a 3.5, so we'd expect our combined list would have it as a 4.\n",
        "\n",
        "**Step 5.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCDA3zTezLBn"
      },
      "source": [
        "combined_rating_dict = {}\n",
        "for k in jabril_rating_dict:\n",
        "  if k in jgb_rating_dict:\n",
        "    combined_rating_dict.update({k: float((jabril_rating_dict[k]+jgb_rating_dict[k])/2)})\n",
        "  else:\n",
        "    combined_rating_dict.update({k:jabril_rating_dict[k]})\n",
        "for k in jgb_rating_dict:\n",
        "   if k not in combined_rating_dict:\n",
        "      combined_rating_dict.update({k:jgb_rating_dict[k]})\n",
        "      \n",
        "print(\"Combined ratings dictionary assembled!\")\n",
        "print(\"Sanity check:\")\n",
        "print(\"\\tCombined rating for 1197 (The Princess Bride) is \" + str(combined_rating_dict[1197]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3boe1yumm0m"
      },
      "source": [
        "Looks like everything checks out. So now, we have a combined dictionary that we can plug right into our User-User model to output a ranked list of new movies that we should both enjoy!\n",
        "\n",
        "**Step 5.2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHOwanSbmoc0"
      },
      "source": [
        "combined_recs = algo.recommend(-1, num_recs, ratings=pd.Series(combined_rating_dict))  #Here, -1 tells it that it's not an existing user in the set, that we're giving new ratings, while 10 is how many recommendations it should generate\n",
        "\n",
        "joined_data = combined_recs.join(data.movies['genres'], on='item')      \n",
        "joined_data = joined_data.join(data.movies['title'], on='item')\n",
        "joined_data = joined_data[joined_data.columns[2:]]\n",
        "print(\"\\n\\nRECOMMENDED FOR JABRIL / JOHN-GREEN-BOT HYBRID:\")\n",
        "joined_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2ztmXUHzah"
      },
      "source": [
        "The number one recommendation is _[Submarine](https://www.imdb.com/title/tt1440292/)_ which is a quirky movie from 2010. If this is too obscure, we could pick a different recommendation from this list like _[True Grit](https://www.imdb.com/title/tt1403865/)_.\n",
        "\n",
        "We could also go back to Step 4.1 and set different parameters. Setting the minimum and maximum number of neighbors to make bigger clusters (for example, a minimum of 10 and and maximum of 50) would probably yield a more well-known set of movies, but it would also be less tailored to our individual interests. The trade-off between unconventional and popular results is what really characterizes recommender systems!"
      ]
    }
  ]
}